
\subsubsection{Scalability Enhancements	to FMM for MD Simulations}
\label{sec.report.ik}

% start new section for referencing, please use the name of your bibfile here instead of report2015 (.bib)
\begin{refsection}[refs_ik]

\paragraph{Participants}~\\
\begin{itemize}
  \item Pavan Balaji (ANL)
  \item Ivo Kabadshow (JSC)
  \item David Haensel (JSC)
\end{itemize}

\paragraph{Research topic and goals}~\\

The goal of this joint-lab cooperation covers the topic of parallel programming. We are especially interested in increasing the scalability (strong scaling) of the Fast Multipole Method (FMM) for very large numbers of ranks. 
FMSolvr is a high-performance FMM library being developed by JSC. However, the current intrinsic parallel scaling limitations stem from process synchronization on large-scale systems. We will investigate weak and delayed synchronization models, tasking approaches and other techniques with MPI-3 and upcoming MPI-4 extensions to alleviate some of these performance bottlenecks.

\paragraph{Results for current year}~\\

The project was initiated at the JLESC meeting in November 2014. 
To provide a consistent interface for measuring and tuning parallel code performance some profound changes had to be made to the code. We started implementing an abstract parallelization layer for the FMSolvr library. This includes a threading approach for intra-node communication as well as a parallelization approach for inter-node communication via MPI. The adopted abstraction layer allows easier replacement/improvement of different synchronization strategies within the code.

Since this is a starting cooperation (\starting) no project publications are available at the moment.
\paragraph{Visits and meetings}~\\

Since this is a starting cooperation no visits have been initiated. The upcoming JLESC meeting at BSC will be used as a first project meeting.

\paragraph{Impact and publications}~\\

none yet.

\paragraph{Person-Month efforts}~\\

20\% of a PhD position (David Haensel, JSC) as well as 5\% of a staff position (Ivo Kabadshow, JSC) have been spent on this activity since December 2014. The efforts are likely to increase, once the code base includes a near-complete parallelization layer.

\paragraph{Future plans}~\\

Next, we want to setup an automatic testing framework for the FMM. This allows us to investigate the scaling bottlenecks of the method without the need to provide a real-world MD dataset. The framework will generate the corresponding input data as well as the required FMM parameter on the fly. After this step is finished an extensive scaling analysis on different HPC platforms will be performed. The results of this analysis are the foundation of all subsequent tuning efforts.


\paragraph{References}~\\

none yet.

% print list of publications not from this project but of other relevance
\printbibliography[heading=none,notkeyword=own]

\end{refsection}
